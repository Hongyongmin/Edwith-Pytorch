{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "9-4 Batch Normalization",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMFGtes9Bu/x/jd+cS1dhOo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hongyongmin/Edwith-Pytorch/blob/main/9_4_Batch_Normalization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_bZhEuHALOP"
      },
      "source": [
        "import torch\r\n",
        "import torchvision.datasets as dsets\r\n",
        "import torchvision.transforms as transforms\r\n",
        "import matplotlib.pylab as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eA-6-powATWK"
      },
      "source": [
        "device  ='cuda' if torch.cuda.is_available() else 'cpu'\r\n",
        "\r\n",
        "torch.manual_seed(1)\r\n",
        "if device == 'cuda':\r\n",
        "  torch.cuda.manual_seed_all(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2esfd3VuAauh"
      },
      "source": [
        "learning_rate = 0.01\r\n",
        "training_epochs = 10\r\n",
        "batch_size = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpoUT9CBAeDH"
      },
      "source": [
        "mnist_train = dsets.MNIST(root='MNIST_data/',\r\n",
        "                          train = True,\r\n",
        "                          transform = transforms.ToTensor(),\r\n",
        "                          download=True)\r\n",
        "\r\n",
        "mnist_test = dsets.MNIST(root='MNIST_data/',\r\n",
        "                         train=False,\r\n",
        "                         transform = transforms.ToTensor(),\r\n",
        "                         download=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MceKXO6RAzqp"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(dataset = mnist_train,\r\n",
        "                                           batch_size = batch_size,\r\n",
        "                                           shuffle = True,\r\n",
        "                                           drop_last = True)\r\n",
        "test_loader = torch.utils.data.DataLoader(dataset = mnist_test,\r\n",
        "                                          batch_size = batch_size,\r\n",
        "                                          shuffle = False,\r\n",
        "                                          drop_last = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPNQy7SjBcE2"
      },
      "source": [
        "linear1 = torch.nn.Linear(784, 32, bias = True)\r\n",
        "linear2 = torch.nn.Linear(32, 32, bias = True)\r\n",
        "linear3 = torch.nn.Linear(32, 10, bias = True)\r\n",
        "relu = torch.nn.ReLU()\r\n",
        "bn1 = torch.nn.BatchNorm1d(32)\r\n",
        "bn2 = torch.nn.BatchNorm1d(32)\r\n",
        " \r\n",
        "nn_linear1 = torch.nn.Linear(784, 32, bias=True)\r\n",
        "nn_linear2 = torch.nn.Linear(32, 32, bias = True)\r\n",
        "nn_linear3 = torch.nn.Linear(32, 10, bias=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qe8Mh1wdB06O"
      },
      "source": [
        "bn_model = torch.nn.Sequential(linear1, bn1, relu,\r\n",
        "                               linear2, bn2, relu,\r\n",
        "                               linear3).to(device)\r\n",
        "\r\n",
        "nn_model = torch.nn.Sequential(nn_linear1, relu,\r\n",
        "                               nn_linear2, relu,\r\n",
        "                               nn_linear3).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k47FAbGgCEdQ"
      },
      "source": [
        "criterion = torch.nn.CrossEntropyLoss().to(device)\r\n",
        "bn_optimizer = torch.optim.Adam(bn_model.parameters(), lr = learning_rate)\r\n",
        "nn_optimizer = torch.optim.Adam(nn_model.parameters(), lr = learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWaf80DSCR5L",
        "outputId": "7c2e5dd9-a6d6-4e92-830f-bce651c99394"
      },
      "source": [
        "train_losses = []\r\n",
        "train_accs = []\r\n",
        "\r\n",
        "valid_losses = []\r\n",
        "valid_accs = []\r\n",
        "\r\n",
        "train_total_batch = len(train_loader)\r\n",
        "test_total_batch = len(test_loader)\r\n",
        "for epoch in range(training_epochs):\r\n",
        "  bn_model.train()\r\n",
        "\r\n",
        "  for X, Y in train_loader:\r\n",
        "\r\n",
        "    X = X.view(-1, 28*28).to(device)\r\n",
        "    Y = Y.to(device)\r\n",
        "\r\n",
        "    bn_optimizer.zero_grad()\r\n",
        "    bn_prediction = bn_model(X)\r\n",
        "    bn_loss = criterion(bn_prediction, Y)\r\n",
        "    bn_loss.backward()\r\n",
        "    bn_optimizer.step()\r\n",
        "\r\n",
        "    nn_optimizer.zero_grad()\r\n",
        "    nn_prediction = nn_model(X)\r\n",
        "    nn_loss = criterion(nn_prediction, Y)\r\n",
        "    nn_loss.backward()\r\n",
        "    nn_optimizer.step()\r\n",
        "\r\n",
        "  with torch.no_grad():\r\n",
        "    bn_model.eval()\r\n",
        "\r\n",
        "    bn_loss, nn_loss, bn_acc, nn_acc = 0, 0, 0, 0\r\n",
        "    for i, (X, Y) in enumerate(train_loader):\r\n",
        "      X = X.view(-1, 28*28).to(device)\r\n",
        "      Y = Y.to(device)\r\n",
        "\r\n",
        "      bn_prediction = bn_model(X)\r\n",
        "      bn_correct_prediction = torch.argmax(bn_prediction, 1) ==Y\r\n",
        "      bn_loss += criterion(bn_prediction, Y)\r\n",
        "      bn_acc += bn_correct_prediction.float().mean()\r\n",
        "\r\n",
        "      nn_prediction = nn_model(X)\r\n",
        "      nn_correct_prediction = torch.argmax(nn_prediction, 1) ==Y\r\n",
        "      nn_loss += criterion(nn_prediction, Y)\r\n",
        "      nn_acc += nn_correct_prediction.float().mean()\r\n",
        "\r\n",
        "    bn_loss, nn_loss, bn_acc, nn_acc = bn_loss / train_total_batch, nn_loss / train_total_batch, bn_acc / train_total_batch, nn_acc / train_total_batch\r\n",
        "\r\n",
        "    train_losses.append([bn_loss, nn_loss])\r\n",
        "    train_accs.append([bn_acc, nn_acc])\r\n",
        "    print(\r\n",
        "        '[Epoch %d-TRAIN] Batchnorm Loss(Acc): bn_loss:%.5f(bn_acc:%.2f) vs No Batchnorm Loss(Acc): nn_loss:%.5f(nn_acc:%.2f)'\r\n",
        "         %((epoch +1), bn_loss.item(), bn_acc.item(), nn_loss.item(), nn_acc.item()))\r\n",
        "    \r\n",
        "    for i, (X, Y) in enumerate(test_loader):\r\n",
        "            X = X.view(-1, 28 * 28).to(device)\r\n",
        "            Y = Y.to(device)\r\n",
        "\r\n",
        "            bn_prediction = bn_model(X)\r\n",
        "            bn_correct_prediction = torch.argmax(bn_prediction, 1) == Y\r\n",
        "            bn_loss += criterion(bn_prediction, Y)\r\n",
        "            bn_acc += bn_correct_prediction.float().mean()\r\n",
        "\r\n",
        "            nn_prediction = nn_model(X)\r\n",
        "            nn_correct_prediction = torch.argmax(nn_prediction, 1) == Y\r\n",
        "            nn_loss += criterion(nn_prediction, Y)\r\n",
        "            nn_acc += nn_correct_prediction.float().mean()\r\n",
        "\r\n",
        "    bn_loss, nn_loss, bn_acc, nn_acc = bn_loss / train_total_batch, nn_loss / train_total_batch, bn_acc / train_total_batch, nn_acc / train_total_batch\r\n",
        "\r\n",
        "\r\n",
        "        # Save valid losses/acc\r\n",
        "    valid_losses.append([bn_loss, nn_loss])\r\n",
        "    valid_accs.append([bn_acc, nn_acc])\r\n",
        "    print(\r\n",
        "            '[Epoch %d-VALID] Batchnorm Loss(Acc): bn_loss:%.5f(bn_acc:%.2f) vs No Batchnorm Loss(Acc): nn_loss:%.5f(nn_acc:%.2f)' % (\r\n",
        "                (epoch + 1), bn_loss.item(), bn_acc.item(), nn_loss.item(), nn_acc.item()))\r\n",
        "    print()\r\n",
        "\r\n",
        "print('Learning finished')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Epoch 1-TRAIN] Batchnorm Loss(Acc): bn_loss:0.10442(bn_acc:0.97) vs No Batchnorm Loss(Acc): nn_loss:0.19405(nn_acc:0.94)\n",
            "[Epoch 1-VALID] Batchnorm Loss(Acc): bn_loss:0.02028(bn_acc:0.16) vs No Batchnorm Loss(Acc): nn_loss:0.03679(nn_acc:0.16)\n",
            "\n",
            "[Epoch 2-TRAIN] Batchnorm Loss(Acc): bn_loss:0.08397(bn_acc:0.97) vs No Batchnorm Loss(Acc): nn_loss:0.18143(nn_acc:0.95)\n",
            "[Epoch 2-VALID] Batchnorm Loss(Acc): bn_loss:0.01756(bn_acc:0.16) vs No Batchnorm Loss(Acc): nn_loss:0.03740(nn_acc:0.16)\n",
            "\n",
            "[Epoch 3-TRAIN] Batchnorm Loss(Acc): bn_loss:0.07141(bn_acc:0.98) vs No Batchnorm Loss(Acc): nn_loss:0.13216(nn_acc:0.96)\n",
            "[Epoch 3-VALID] Batchnorm Loss(Acc): bn_loss:0.01660(bn_acc:0.16) vs No Batchnorm Loss(Acc): nn_loss:0.03098(nn_acc:0.16)\n",
            "\n",
            "[Epoch 4-TRAIN] Batchnorm Loss(Acc): bn_loss:0.06997(bn_acc:0.98) vs No Batchnorm Loss(Acc): nn_loss:0.14292(nn_acc:0.96)\n",
            "[Epoch 4-VALID] Batchnorm Loss(Acc): bn_loss:0.01678(bn_acc:0.16) vs No Batchnorm Loss(Acc): nn_loss:0.03436(nn_acc:0.16)\n",
            "\n",
            "[Epoch 5-TRAIN] Batchnorm Loss(Acc): bn_loss:0.06430(bn_acc:0.98) vs No Batchnorm Loss(Acc): nn_loss:0.12236(nn_acc:0.97)\n",
            "[Epoch 5-VALID] Batchnorm Loss(Acc): bn_loss:0.01660(bn_acc:0.16) vs No Batchnorm Loss(Acc): nn_loss:0.02864(nn_acc:0.16)\n",
            "\n",
            "[Epoch 6-TRAIN] Batchnorm Loss(Acc): bn_loss:0.06129(bn_acc:0.98) vs No Batchnorm Loss(Acc): nn_loss:0.12701(nn_acc:0.96)\n",
            "[Epoch 6-VALID] Batchnorm Loss(Acc): bn_loss:0.01769(bn_acc:0.16) vs No Batchnorm Loss(Acc): nn_loss:0.02954(nn_acc:0.16)\n",
            "\n",
            "[Epoch 7-TRAIN] Batchnorm Loss(Acc): bn_loss:0.05561(bn_acc:0.98) vs No Batchnorm Loss(Acc): nn_loss:0.11742(nn_acc:0.97)\n",
            "[Epoch 7-VALID] Batchnorm Loss(Acc): bn_loss:0.01566(bn_acc:0.16) vs No Batchnorm Loss(Acc): nn_loss:0.03136(nn_acc:0.16)\n",
            "\n",
            "[Epoch 8-TRAIN] Batchnorm Loss(Acc): bn_loss:0.05146(bn_acc:0.98) vs No Batchnorm Loss(Acc): nn_loss:0.10029(nn_acc:0.97)\n",
            "[Epoch 8-VALID] Batchnorm Loss(Acc): bn_loss:0.01571(bn_acc:0.16) vs No Batchnorm Loss(Acc): nn_loss:0.02882(nn_acc:0.16)\n",
            "\n",
            "[Epoch 9-TRAIN] Batchnorm Loss(Acc): bn_loss:0.04868(bn_acc:0.98) vs No Batchnorm Loss(Acc): nn_loss:0.12389(nn_acc:0.97)\n",
            "[Epoch 9-VALID] Batchnorm Loss(Acc): bn_loss:0.01488(bn_acc:0.16) vs No Batchnorm Loss(Acc): nn_loss:0.03429(nn_acc:0.16)\n",
            "\n",
            "[Epoch 10-TRAIN] Batchnorm Loss(Acc): bn_loss:0.04562(bn_acc:0.99) vs No Batchnorm Loss(Acc): nn_loss:0.10188(nn_acc:0.97)\n",
            "[Epoch 10-VALID] Batchnorm Loss(Acc): bn_loss:0.01486(bn_acc:0.16) vs No Batchnorm Loss(Acc): nn_loss:0.03135(nn_acc:0.16)\n",
            "\n",
            "Learning finished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACCXheNlEJFW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}